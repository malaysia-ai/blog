{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40e41d09",
   "metadata": {},
   "source": [
    "# Mykad Information Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fef41ec",
   "metadata": {},
   "source": [
    "I use all my remaining carry forward leaves this week and today don't know what to do. I decided to work on writing blog post since already 6 months I did not post anything new. Today I will write about how to do MyKad Information Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83314040",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0554718",
   "metadata": {},
   "source": [
    "Everytime working on machine learning project the first thing you need to know and acquire are data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac17a9a7",
   "metadata": {},
   "source": [
    "For this one I only label around 100 images since I'm gonna finetuned on pretrained model and heavy augmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86f0b62",
   "metadata": {},
   "source": [
    "This is example annotation I label using coco-annotator(usually I use label studio, but today I want to try new stuff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb453510",
   "metadata": {},
   "source": [
    "![](./artifacts/ex.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e160b65",
   "metadata": {},
   "source": [
    "![](./artifacts/image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb482cfa",
   "metadata": {},
   "source": [
    "![](./artifacts/anno.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c5689c",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea8a91b",
   "metadata": {},
   "source": [
    "For model, I choose SOTA for object detection which is YOLOX. In simple term YOLOX is **anchor-free** version of YOLO with advanced detection techniques, i.e., a **decoupled head** and the leading label assignment strategy **SimOTA**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bd6f54",
   "metadata": {},
   "source": [
    "![](./artifacts/yolox.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49cda03",
   "metadata": {},
   "source": [
    "The tools I'm using for training object detection model is mmdetection. With mmdet, you only need to modify existing config(data path,hyperparams etc) and run your training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ec8a45",
   "metadata": {},
   "source": [
    "Here some introduction to openmmlab by my friend takuoko-san [slides](https://docs.google.com/presentation/d/e/2PACX-1vTiPEWlJnwuCq6CgrO_hbaz3RVN4xSr5w1AzYHPDtjAw571jXUVxRyTXxaDxbj8RqI0e8Uauunfct7G/pub?start=false&loop=false&delayms=3000&slide=id.p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c862a6",
   "metadata": {},
   "source": [
    "### Training logs\n",
    "![](./artifacts/logs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bda24a",
   "metadata": {},
   "source": [
    "So far I only managed to localize text in MyKad, but I still not able to get the text from the pixel inside predicted bounding box "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c65e8c",
   "metadata": {},
   "source": [
    "After playing around with some existing OCR model, I found that EasyOCR is the most accurate for my val set.\n",
    "Even though it is not accurate, we can fine tune the model based on this [documentation](https://github.com/JaidedAI/EasyOCR/tree/master/trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643e9b34",
   "metadata": {},
   "source": [
    "## Result\n",
    "Image below is just some MyKad image I found from Google, this one not in the training set.\n",
    "![](./artifacts/debug.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0542ecb2",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47921b00",
   "metadata": {},
   "source": [
    "I'm not gonna say that this model is good enough that will be useful for production, but at least can be use as baseline or poc. For example, you can use this model for e-KYC, some e-KYC they let the user capture their MyKad within the bounding box which is I think might work since the training data got similar kind way it being captured. If the MyKad being capture while the person holding the card and take selfie like what I saw from leaked ekyc photo from SPR database. Honestly not sure gonna work(might work if use use sahi during inference) but at least can create a val/test data similar to that and working on write augmentation method like put mykad image at person hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94a077b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61e0c00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
